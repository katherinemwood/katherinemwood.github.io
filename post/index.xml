<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Inattentional Coffee</title>
    <link>https://katherinemwood.github.io/post/</link>
    <description>Recent content in Posts on Inattentional Coffee</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Katherine</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Program better, for fun and for profit</title>
      <link>https://katherinemwood.github.io/post/programming/</link>
      <pubDate>Mon, 26 Jun 2017 14:35:49 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/programming/</guid>
      <description>&lt;p&gt;Psych researchers have a bit of a reputation for being, shall we say, less-than-delicate programmers. It’s common to hear “it doesn’t matter if it’s ugly, as long as it works.”&lt;/p&gt;
&lt;p&gt;I took computer science classes as an undergrad, and style was rigidly enforced. I had one notoriously strict professor who would dock up to a grade on an otherwise completely functional project if it was ugly. It wasn’t just simple elitism; ugly code is often inefficient code, and ugly code is hard to read and understand.&lt;/p&gt;
&lt;p&gt;Code quality is something I’m constantly working on. You can see the development in my scripts; I only recently started using dplyr and the rest of the tidyverse in R, and what a difference it’s made to the quality of my code. I cringe a little, looking back at my earliest scripts (and they’re a matter of public record, forever). Cringe is good, though. Cringe signals improvement, and wisdom gained.&lt;/p&gt;
&lt;p&gt;I thought I’d share a few of the practices that were drilled into me during my CS education that have helped improve the style, quality, and readability of my code.&lt;/p&gt;
&lt;div id=&#34;comment-your-code.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;1. Comment your code.&lt;/h1&gt;
&lt;p&gt;Please. If not for others, then for your future self. You will neither remember nor understand your code in the future as well as you think you will. I don’t to it as thoroughly as I ought; I’m not sure anyone does. This is easy to change, and doesn’t take much effort.&lt;/p&gt;
&lt;p&gt;Functions should be commented with what their inputs are, what it does to those inputs, and what it returns. For a gold star, you can include examples of input and output.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;&amp;#39;&amp;#39;&amp;#39;
A function that takes in a list of integers X
and returns the arithmetic mean in floating-point
form.
&amp;#39;&amp;#39;&amp;#39;
def mean(x):
    return(sum(x)/float(len(x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Global variables should be commented with what they are and how they’re used, so that you can change them without having to dig back through the code to make sure you understand what the variable does.&lt;/p&gt;
&lt;p&gt;Commenting code makes it much easier for others to understand, and it cuts way down on re-learning if you have to go back and revisit old code.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-sensible-variable-and-function-names.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;2. Use sensible variable and function names.&lt;/h1&gt;
&lt;p&gt;It very rapidly becomes impossible to tell what is happening when all variables are named &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;x1&lt;/code&gt;, &lt;code&gt;x2&lt;/code&gt;, or &lt;code&gt;tmp&lt;/code&gt;. While we want variable names to be succinct, they should also make sense and be recognizable. Degrees of freedom can be &lt;code&gt;df&lt;/code&gt;. A subject’s height could be &lt;code&gt;subj_height&lt;/code&gt;, rather than, say, &lt;code&gt;h&lt;/code&gt; or &lt;code&gt;s_h&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This is also good to do when you’re subsetting data. You don’t want to confuse yourself or others about which variable represents the full dataset, and which represents a subset!&lt;/p&gt;
&lt;p&gt;Functions should also, ideally, be named after what they do. &lt;code&gt;cartesian_to_polar(x, y)&lt;/code&gt; is obvious (if you know your coordinate systems); &lt;code&gt;c2p(x, y)&lt;/code&gt; less so.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;avoid-hardcoding.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;3. Avoid hardcoding.&lt;/h1&gt;
&lt;p&gt;“Hardcoding” is the practice of writing explicit, fixed values into functions and scripts instead of variables. So if you had a run_experiment function, hardcoded to do 100 trials, it might look like this:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def run_experiment():
    for i in range(100):
        do_trial(i)
do_other_stuff(i)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then maybe at the end of the script, you have to reference the number of trials again, maybe to calculate percent correct:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#let&amp;#39;s assume for convenience that yes_responses is a list of bools
correct_resp = sum(yes_responses)/100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This works fine, but what if you decide to change the number of trials? Then you’ll have to hunt back through every place you used 100 and change it. What would be a lot easier is to define a variable, num_trials, at the beginning of your script. Then, every time you need to reference this number, use num_trials rather than the hard number. Then, if you change your mind, you only have to change the value of num_trials to change its value everywhere else in the script.&lt;/p&gt;
&lt;p&gt;This is especially relevant for experiment scripts, in which values might change over the course of development, or need to change during the experiment itself with the condition or trial type. It’s much more convenient to have all of you parameters mapped to variables in one place so that you only have to change them once to change behavior everywhere. Changes become easy and quick, and it will save heartache.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;think-modular.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;4. Think modular.&lt;/h1&gt;
&lt;p&gt;Break routines and operations into functions, particularly if you have to do them over and over again. For example, if you’re writing an experiment, you might want to have a function that handles a single trial, with some inputs that can be adjusted. Maybe you have long-exposure trials and short-exposure trials, for instance. It’s nice to be able to call &lt;code&gt;do_trial(long_ontime)&lt;/code&gt; or &lt;code&gt;do_trial(short_ontime)&lt;/code&gt;, rather than having all of that logic imbedded in one monster script. If you need more flexibility, just write the function to accept more variables and pass them in.&lt;/p&gt;
&lt;p&gt;If you have a function that you use a lot (I have one for saving out data), you can keep it in a separate file and source it in each time you need it, rather than rewriting it each time. Being able to re-use your code saves time and effort.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;be-succinct.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;5. Be succinct.&lt;/h1&gt;
&lt;p&gt;Often, there’s a verbose way to do something, and a concise way to do something. For instance, in Python, you can very often replace for-loops with list comprehensions. In R, just about every for-loop can be replaced with a combination of calls to the venerable &lt;code&gt;apply&lt;/code&gt; family of functions or to higher-order functions like &lt;code&gt;Reduce&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/web/packages/tidyverse/index.html&#34;&gt;&lt;code&gt;tidyverse&lt;/code&gt;&lt;/a&gt;, a diverse set of packages for R, makes many common data manipulation commands into short primitives. This can clean up and shorten code substantially, especially when extensive data manipulation is involved (see &lt;a href=&#34;https://katherinemwood.github.io/post/wrangling/&#34;&gt;this post&lt;/a&gt; for examples of it in action and how it compares to other base methods). It tends to be less verbose and more readable, although the latter is subjective to a point.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;unit-test.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;6. Unit-test.&lt;/h1&gt;
&lt;p&gt;This is an example of doing more work now to do less work later. I’ve fallen out of the habit of unit-testing, but with the new year comes an opportunity to return to core values.&lt;/p&gt;
&lt;p&gt;In unit-testing, you write tests in a separate script for little pieces of your code. This is &lt;a href=&#34;https://docs.python.org/2/library/unittest.html&#34;&gt;easy in Python&lt;/a&gt;, and there’s a &lt;a href=&#34;https://cran.r-project.org/web/packages/testthat/testthat.pdf&#34;&gt;nice R package for it too&lt;/a&gt;. See &lt;a href=&#34;https://katherinemwood.github.io/post/testthat/&#34;&gt;this post&lt;/a&gt; to see it in action.&lt;/p&gt;
&lt;p&gt;The idea is that you test each piece of code (functions, object classes, etc) as you write it and verify that it works. Even better, you can write tests for code first, before you even write the code itself. Tests make sure that code runs without crashing, that the output it gives you matches what you expect, that objects have the methods and attributes you want and that they all do what you expect, and so on.&lt;/p&gt;
&lt;p&gt;Why bother? For one, it creates a nice feedback loop with modularity. Writing code in nice little packages makes it easy to test, which encourages writing code in nice little packages, etc. Two, it will save you a ton of time during debugging. If you write an entire script through, try to run it, and almost inevitably encounter bugs, you then have to search through a lot of possible failure points. Usually that means having to verify that all of the pieces work anyway, in order to zero in on the culprit(s). With unit testing, you know right away whether something is working and if it’s working correctly. This gives you a chance to fix things before you run the whole thing through.&lt;/p&gt;
&lt;p&gt;Following good practices only nets benefits. It makes your old code more accessible to yourself. Possibly more critically, it makes your code more accessible to others. Open data and open materials are becoming more common, and it’s not enough just to throw uncommented code up on Github and call it duty done. Part of that responsibility to openness is making code readable, understandable, and transparent.These practices are a good place to start.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>5 Minute Simulation: Variation in effect size estimates</title>
      <link>https://katherinemwood.github.io/post/es_var/</link>
      <pubDate>Mon, 26 Jun 2017 13:54:20 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/es_var/</guid>
      <description>&lt;p&gt;If it’s not terribly obvious, &lt;a href=&#34;http://shiny.rstudio.com/tutorial/&#34;&gt;Shiny&lt;/a&gt; is my new favorite toy. It’s incredibly accessible for beginners, gives you great results with minimal effort, and can be as sophisticated as you need it to be.&lt;/p&gt;
&lt;p&gt;I decided to throw together a quick simulation to look at the variation in effect size estimates we can expect at different sample sizes. There’s an increasing focus in psych on estimation of effects, rather than simply detection of effects. This is great, but, as it turns out, virtually impossible with a single study unless you are prepared to recruit massive numbers of subjects. Nothing here is new, but I like looking at distributions and playing with sliders, and I’ll take any excuse to make a little shiny widget.&lt;/p&gt;
&lt;p&gt;In this simulation, we’re doing a basic, between-groups t-test and drawing samples from the normal distribution. The code can be dead simple. I’ll write a tiny&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

sim_es &amp;lt;- function(n, true_es) {
  g1 &amp;lt;- rnorm(n, true_es, 1)
  g2 &amp;lt;- rnorm(n, 0, 1)
  return(effsize::cohen.d(g1, g2, paired=FALSE)$estimate)
}

plot_es &amp;lt;- function(data, true_es) {
  es_plot &amp;lt;- ggplot() +
      theme_minimal() +
      geom_histogram(aes(x=data, y=..count../sum(..count..)), 
               color=&amp;#39;darkblue&amp;#39;, fill=&amp;#39;darkblue&amp;#39;, position=&amp;#39;identity&amp;#39;) +
      geom_vline(xintercept=c(true_es,
                              sort(data)[.975*length(data)], 
                              sort(data)[.025*length(data)]), 
                 size=1.5, color=c(&amp;#39;lightgray&amp;#39;, &amp;#39;red&amp;#39;, &amp;#39;red&amp;#39;), 
                 linetype=c(&amp;#39;solid&amp;#39;, &amp;#39;longdash&amp;#39;,&amp;#39;longdash&amp;#39;)) +
      xlab(&amp;quot;Effect size&amp;quot;) +
      ylab(&amp;#39;Proportion&amp;#39;) +
      xlim(c(-2, 2))

  print(es_plot)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what you get if you use tiny (n=10) groups (perhaps under the justification that if an effect is big, you’ll detect it just fine in small samples) and no true effect is present:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n10 &amp;lt;- replicate(3000, sim_es(10, 0))
plot_es(n10, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://katherinemwood.github.io/post/es_var_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The white line is the true effect, and the two red lines mark out the 95% quantile.&lt;/p&gt;
&lt;p&gt;Yikes. With samples that small, you could (and will, often!) get an enormous effect when none is present.&lt;/p&gt;
&lt;p&gt;Here’s what we get with n = 50, no effect present. I’ve left the x-axis fixed to make it easier to compare all of these plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n50 &amp;lt;- replicate(3000, sim_es(50, 0))
plot_es(n50, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://katherinemwood.github.io/post/es_var_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is a dramatic improvement over n=10, but you could still estimate what is considered a small (d=.1, traditionally) to medium (d=.3, traditionally) effect in either direction with appreciable frequency.&lt;/p&gt;
&lt;p&gt;And here’s n=200.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n200 &amp;lt;- replicate(3000, sim_es(200, 0))
plot_es(n200, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://katherinemwood.github.io/post/es_var_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I’ve used d=0 as an example, but you get this spread regardless of what the true d is; it will just shift to center on the true effect. In that case, you’ll detect an effect most of the time, but can be way off about its actual size. This doesn’t mean that you can throw power out the window by arguing that you only care about detection, of course–you’ll “detect” an effect a lot of the time when d=0 with small samples.&lt;/p&gt;
&lt;p&gt;These simulations are the result of 3000 replications each, but in the shiny app you can change this number.&lt;/p&gt;
&lt;p&gt;For me, this really drives home just how important replications and meta-analyses–cumulative science in general, really–are, particularly for estimation. When you do a lot of these studies over and over again, as these simulations model, you’ll zero in on the true effect, but a study can’t do it alone.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://katherinemwood.shinyapps.io/effect_size/&#34;&gt;The Shiny app can be found here&lt;/a&gt;. You can tweak group size, true effect size, how many simulations are run, and the limits on the x-axis. You can also view a plot of the corresponding p-values.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/katherinemwood/es_variation&#34;&gt;The source code can be found here.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Open Science in Practice</title>
      <link>https://katherinemwood.github.io/post/open_sci/</link>
      <pubDate>Mon, 26 Jun 2017 13:48:35 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/open_sci/</guid>
      <description>&lt;p&gt;I will finish grad school a child of the replication crisis. My year and a half in grad school has been marked by bombshell failures-to-replicate, increasing adoption of Bayesian methods, and wider recognition of the insidious effects of questionable research practices.&lt;/p&gt;
&lt;p&gt;In many ways, I’m lucky. I didn’t have to make changes to the way I did things to adhere to better practices. I got to start with openness as one of the core tenets of how I conduct my research, and starting fresh is always easier than having to alter pre-existing patterns of behavior. It also helps to have a huge proponent of replication and open science as an advisor and to have come in at a time when there’s fantastic infrastructure in place.&lt;/p&gt;
&lt;p&gt;Here’s an example of what my process looks like. A lot of this has already been said by better minds, and none of what I do is revolutionary. But it can, perhaps, serve as an illustration of what it looks like to actually build these practices into your workflow.&lt;/p&gt;
&lt;div id=&#34;planning-and-preregistration&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. Planning and preregistration&lt;/h2&gt;
&lt;p&gt;Once my advisor and I have finalized the approach to our next experiment, the preparation phase begins. I write-up and test my experiment script by running through the entire thing, as a subject would (and try to break it as a subject might).&lt;/p&gt;
&lt;p&gt;Because I’ve written the experiment script, I know exactly how the data will be saved out. This lets me write the entire analysis script, including wrangling, pre-processing, and figure generation. I test the functionality of the script on dummy data I generate during testing my experiment and make sure it runs properly.&lt;/p&gt;
&lt;p&gt;After this is done, it’s time to preregister–I like to do so at the &lt;a href=&#34;https://osf.io/&#34;&gt;Open Science Framework&lt;/a&gt;. I outline my hypotheses and upload hypothetical data figures if my predictions are sufficiently specific. I describe all of my experiment methods in gory detail, including all measures collected, and attach my experimental script and any stimuli I use. I detail exactly which hypotheses I’m going to test, and how (which statistical test; how many tails, if applicable; the values of any parameters, such as priors for Bayes Factors, etc.). I explicitly state how many subjects we’ll be running and how we’re going to exclude subjects from analysis. I also upload my analysis script and any helper functions or files.&lt;/p&gt;
&lt;p&gt;Once all of these things are in place, I preregister the project. My preferred method is to enter it into embargo, and then make the project public after the paper has been submitted.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-collection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. Data collection&lt;/h2&gt;
&lt;p&gt;This tends to be uneventful, since everything has been battle-tested and all decision have already been made. I do not examine the data, even just to look, as it comes in, so that if something unforeseen emerges that requires a change to protocol, I can make a new preregistration on OSF and affirm that it has been done in absence of knowledge of the data. I collect as many subjects as I said I would in my preregistration.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. Analysis&lt;/h2&gt;
&lt;p&gt;This also goes lightning-fast, because the script is already written. I just run the data through it, and know the results that I will be reporting as confirmatory immediately (no strolls through the garden of forking paths). This is great for me, because I cannot handle suspense when it comes to knowing the outcome of my experiments.&lt;/p&gt;
&lt;p&gt;That done, I can then poke around a little and explore the data if I wish, or do some robustness analyses. Anything that comes from this needs to be reported as exploratory if it is reported at all.&lt;/p&gt;
&lt;p&gt;I make sure to plot my raw data. Ideally I like to plot it along with my summary values in something like a violin plot (I like to do the raw points over the violin density graph, plus a line showing the mean and maybe some confidence intervals). It’s always a good idea to know the ins and outs of your data, which requires knowing what the raw distributions look like.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;post-raw-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4. Post raw data&lt;/h2&gt;
&lt;p&gt;After the analysis is done, I add the raw data in its entirety to the project’s OSF page and include with it a README that provides detailed instructions on how to interpret the data. This has the nice added benefit of creating a secure backup of my data then and there.&lt;/p&gt;
&lt;p&gt;The project is still private at this point.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reporting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;5. Reporting&lt;/h2&gt;
&lt;p&gt;After repeating steps 1-4 as necessary for follow-up experiments, I write up the manuscript. The methods section is easy, as I pretty much wrote it already back in step 1. I make sure to include a link to my OSF page for the project, which I make public when submitting the manuscript, and include language making it clear that we report all conditions and measures.&lt;/p&gt;
&lt;p&gt;When we report our stats, we include all information necessary to recreate our analyses. This means correlations for within-subjects designs and cell means for ANOVAs. We also make sure to report how many people were excluded and what proportion of our sample that represents, and how many people ended up assigned to each condition, if applicable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pre-prints&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;6. Pre-prints&lt;/h2&gt;
&lt;p&gt;After the manuscript has been accepted (I’ll take Wishful Thinking for $800, Alex), I upload a preprint of the accepted version to PsyarXiv. I will do this for all of my papers, but I think it’s especially important in cases where one cannot publish open access. Most journals will tell you what the policy is regarding posting the paper to external sources.&lt;/p&gt;
&lt;p&gt;You can, of course, post a preprint before the paper has been accepted (most of the time this will not preclude later publishing in a journal), but my papers tend to undergo radical transformation during peer review, so I prefer to post a more final version.&lt;/p&gt;
&lt;p&gt;And that’s my process. Integrating open science and best research practices takes a little practice, but once you’ve gotten comfortable with your workflow it’s as easy as any other habit (and comes with a lot of benefits for your trouble).&lt;/p&gt;
&lt;p&gt;This workflow works pretty well for me, but I think it can be better. This year I would like to start using figshare, and do version control for my scripts with GitHub, and look into using RMarkdown for papers. There’s always more to learn!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>5 Minute Simulation: Lonely Cards</title>
      <link>https://katherinemwood.github.io/post/lonely_cards/</link>
      <pubDate>Mon, 26 Jun 2017 12:34:18 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/lonely_cards/</guid>
      <description>&lt;p&gt;FiveThirtyEight posts math, logic, and probability puzzles each week. I was tempted by this week’s &lt;a href=&#34;http://fivethirtyeight.com/features/can-you-deal-with-these-card-game-puzzles/&#34;&gt;Riddler Express&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;On snowy afternoons, you like to play a solitaire “game” with a standard, randomly shuffled deck of 52 cards. You start dealing cards face up, one at a time, into a pile. As you deal each card, you also speak aloud, in order, the 13 card faces in a standard deck: ace, two, three, etc. (When you get to king, you start over at ace.) You keep doing this until the rank of the card you deal matches the rank you speak aloud, in which case you lose. You win if you reach the end of the deck without any matches.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;What is the probability that you win?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My combinatorics skills are rusty, so I’m still hacking away at the closed-form solution. But, where cunning fails, brute force may suffice. While the closed-form approach is proving challenging (for me), this is fairly trivial to approximate through simulation. Recreating the game itself only takes a line or two of code, and then we can “play” hundreds of thousands of simulated games to get an idea of how often we win. &lt;a href=&#34;https://katherinemwood.shinyapps.io/lonely_cards/&#34;&gt;Here’s a simple shiny app&lt;/a&gt; with the results, and here’s the dead-simple code for simulating the game itself:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cards &amp;lt;- function() {
#make a deck; leave this sequence fixed for the verbal sequence,
#and scramble it to simulate the cards being dealt
deck &amp;lt;- rep(c(&amp;#39;ace&amp;#39;, as.character(seq(2:10)),
&amp;#39;jack&amp;#39;, &amp;#39;queen&amp;#39;, &amp;#39;king&amp;#39;), times=4)
#You win if none of the ranks line up; you lose if one or more does
return(as.numeric(!(sum(deck == sample(deck)) &amp;gt; 0))) #1 is win, 0 is lose
}
results &amp;lt;- replicate(100000, cards())
paste(&amp;#39;Win percentage: &amp;#39;, sum(results)/1000,&amp;#39;%&amp;#39;, sep=&amp;#39;&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Win percentage: 1.67%&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll update this post with the closed-form solution if I manage to work it out (failing that, I’ll just link to the solution on FiveThirtyEight).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/katherinemwood/lonely_cards&#34;&gt;Here’s the source code&lt;/a&gt; for the shiny app.&lt;/p&gt;
&lt;p&gt;UPDATE: It turns out the &lt;a href=&#34;https://fivethirtyeight.com/features/how-long-will-it-take-to-blow-out-the-birthday-candles/#correction&#34;&gt;closed-form solution to this riddle&lt;/a&gt; is nontrivial! It relies on a branch of combinatorics called &lt;a href=&#34;http://mathworld.wolfram.com/Derangement.html&#34;&gt;“derangements”&lt;/a&gt; I didn’t encounter in my (admittedly less than comprehensive) math and stats education.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
