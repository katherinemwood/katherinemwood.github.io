<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HOME on Katherine Wood</title>
    <link>https://katherinemwood.github.io/</link>
    <description>Recent content in HOME on Katherine Wood</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© Katherine Wood</copyright>
    <lastBuildDate>Sun, 01 Mar 2020 19:47:09 +0200</lastBuildDate>
    
	<atom:link href="https://katherinemwood.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>PRecall</title>
      <link>https://katherinemwood.github.io/projects/precall/</link>
      <pubDate>Sun, 01 Mar 2020 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/projects/precall/</guid>
      <description>Unsafe or defective products cost over a trillion dollars each year in deaths, injuries, property damage, and lost productivity. It&amp;rsquo;s imperative that consumers be able to avoid unsafe products, but it&amp;rsquo;s currently extremely difficult to find relevant information about recalls or complaints about products.
Using recall announcements and consumer complaints filed to the CPSC, I developed an app that surfaces information related to a product. A consumer can search for a product and receive all the related complaints about that product.</description>
    </item>
    
    <item>
      <title>Multiple Object Tracking</title>
      <link>https://katherinemwood.github.io/projects/simple_mot/</link>
      <pubDate>Thu, 02 Jan 2020 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/projects/simple_mot/</guid>
      <description>This is a script that runs a complete inattentional blindness experiment using multiple object tracking as the main task, including data saving. Many parameters can be changed to control the appearance and behavior of the experiment. Almost every aspect of the experiment is built in an object-oriented way, making it easy to extend.</description>
    </item>
    
    <item>
      <title>Now or never: noticing occurs early in sustained inattentional blindness</title>
      <link>https://katherinemwood.github.io/publications/ib_timing/</link>
      <pubDate>Fri, 01 Nov 2019 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/publications/ib_timing/</guid>
      <description>Abstract People can show sustained inattentional blindness for unexpected objects visible for seconds or even minutes. Would such objects eventually be noticed given enough time, with the likelihood of noticing accumulating while the unexpected object is visible? Or, is there a narrow window around onset or offset when an object is most likely to be detected, with the chances of noticing dropping outside of that window? Across three experiments (total n&amp;rsquo;s = 283, 756, 488) exploring the temporal dynamics of noticing in sustained inattentional blindness, subjects who noticed the unexpected object did so soon after it onset.</description>
    </item>
    
    <item>
      <title>The spatial allocation of attention in an interactive environment</title>
      <link>https://katherinemwood.github.io/publications/interactive_ib/</link>
      <pubDate>Tue, 01 Oct 2019 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/publications/interactive_ib/</guid>
      <description>Abstract Inattentional blindness methods allow for an unobtrusive measure of the spatial distribution of attention; because subjects do not expect the critical object, they have no reason to devote attention to task-irrelevant regions in anticipation of it. We used inattentional blindness to examine the spatial allocation of attention in an interactive game in which subjects navigated through a dynamic environment and avoided hazards. Subjects were most likely to notice unexpected objects in the areas with the greatest risk of contact with a hazard, and less likely to notice equally proximal objects in inaccessible areas of the display or areas in which hazards no longer posed a threat.</description>
    </item>
    
    <item>
      <title>As if by magic: An abrupt change in motion direction induces change blindness</title>
      <link>https://katherinemwood.github.io/publications/motion_cb/</link>
      <pubDate>Fri, 01 Mar 2019 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/publications/motion_cb/</guid>
      <description>Abstract Magicians claim that an abrupt change in the direction of movement can attract attention, allowing them to hide their method for a trick in plain sight. In three experiments involving 43 total participants, we tested this claim by examining whether a sudden directional change can induce change blindness. Participants were asked to detect an instantaneous orientation change to a single item in an array of Gabor patches, which occurred as the entire array moved across the display.</description>
    </item>
    
    <item>
      <title>What is it like to run a Registered Replication?</title>
      <link>https://katherinemwood.github.io/post/first-rr/</link>
      <pubDate>Sat, 05 Jan 2019 10:04:53 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/first-rr/</guid>
      <description>Registered replications are generally considered the gold standard of replication studies. What does it take to actually run one?</description>
    </item>
    
    <item>
      <title>Processing without noticing in inattentional blindness: A replication of Moore &amp; Egeth (1997) and Mack &amp; Rock (1998)</title>
      <link>https://katherinemwood.github.io/publications/implicit_ib/</link>
      <pubDate>Mon, 19 Nov 2018 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/publications/implicit_ib/</guid>
      <description>Abstract Surreptitious online measures can reveal processing of stimuli that people did not report noticing or could not describe. People seem to glean everything from low-level Gestalt grouping information to semantic meaning from unattended and unreported stimuli, and this information seems capable of influencing performance and priming semantic judgments. Moore and Egeth (1997) provided evidence that judgements about the lengths of two lines were influenced by the grouping of background dots, even when subjects did not notice the pattern they formed.</description>
    </item>
    
    <item>
      <title>CORVIDS 2.0: Faster, more stable, and now on Windows</title>
      <link>https://katherinemwood.github.io/post/corvids-2.0/</link>
      <pubDate>Tue, 08 May 2018 10:04:53 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/corvids-2.0/</guid>
      <description>We introduce some major improvements.</description>
    </item>
    
    <item>
      <title>CORVIDS</title>
      <link>https://katherinemwood.github.io/projects/corvids/</link>
      <pubDate>Wed, 02 May 2018 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/projects/corvids/</guid>
      <description>Raw data are often unavailable, and all that may remain of a data set are its summary statistics. When these data are integers on a fixed scale, such as Likert-style ratings, and their mean, standard deviation, and sample size are known, it is possible to reconstruct every raw distribution that gives rise to those summary statistics using a system of Diophantine equations. We have developed the open-source program CORVIDS (COmplete Reconstruction of Values In Diophantine Systems) to deterministically reconstruct raw data from summary statistics using this technique.</description>
    </item>
    
    <item>
      <title>CORVIDS: A provably-complete data reconstruction tool</title>
      <link>https://katherinemwood.github.io/post/corvids/</link>
      <pubDate>Mon, 29 Jan 2018 12:36:28 -0600</pubDate>
      
      <guid>https://katherinemwood.github.io/post/corvids/</guid>
      <description>Using the constraints of Likert-scale data to fully reconstruct it.</description>
    </item>
    
    <item>
      <title>Improving a data visualization</title>
      <link>https://katherinemwood.github.io/post/vizfix/</link>
      <pubDate>Sat, 16 Dec 2017 15:11:42 -0600</pubDate>
      
      <guid>https://katherinemwood.github.io/post/vizfix/</guid>
      <description>There&amp;rsquo;s a point at which more information yields negative returns.</description>
    </item>
    
    <item>
      <title>The role of similarity in inattentional blindness: Selective enhancement, selective suppression, or both?</title>
      <link>https://katherinemwood.github.io/publications/ib_similarity/</link>
      <pubDate>Sun, 26 Nov 2017 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/publications/ib_similarity/</guid>
      <description>Abstract When people selectively pay attention to one set of objects and ignore another, unexpected stimuli often go unnoticed. Noticing rates are higher when the unexpected object matches the features of the attended items and lower when it matches those of the ignored items. No prior studies have fully disentangled these aspects of similarity; in previous work, the unexpected object fell on a continuum between the attended and ignored objects, so increasing the similarity to one set of objects necessarily decreased it to the other.</description>
    </item>
    
    <item>
      <title>Pre-screen MTurk workers with custom qualifications</title>
      <link>https://katherinemwood.github.io/post/qualifications/</link>
      <pubDate>Mon, 09 Oct 2017 15:25:40 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/qualifications/</guid>
      <description>How to set up custom qualification tests to screen MTurk workers.</description>
    </item>
    
    <item>
      <title>Getting started with the Mechanical Turk API</title>
      <link>https://katherinemwood.github.io/post/aws-startup/</link>
      <pubDate>Sun, 08 Oct 2017 15:25:40 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/aws-startup/</guid>
      <description>How to get set up with AWS and Mechanical Turk.</description>
    </item>
    
    <item>
      <title>Selective attention in inattentional blindness: Selection is specific but suppression is not</title>
      <link>https://katherinemwood.github.io/publications/ib_color/</link>
      <pubDate>Mon, 07 Aug 2017 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/publications/ib_color/</guid>
      <description>Abstract When we selectively attend to one set of objects and ignore another, we often fail to notice unexpected events. The likelihood of noticing varies depending on the similarity of an unexpected object to other items in the display, a process thought to be controlled by the attention set that we create for the attended and ignored objects. It remains unclear, though, how attention sets are formed and structured. Do they enhance features of attended objects (âwhiteâ) and suppress features of ignored objects (âblackâ), or do they distinguish objects based on relations or categories (âdarkerâ versus âlighter,â or âdark objectsâ versus âlight objectsâ)?</description>
    </item>
    
    <item>
      <title>Starter tips on sharing data and analysis scripts</title>
      <link>https://katherinemwood.github.io/post/data-sharing/</link>
      <pubDate>Wed, 02 Aug 2017 20:12:31 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/data-sharing/</guid>
      <description>Getting your materials ready for public release.</description>
    </item>
    
    <item>
      <title>Considerations when writing a preregistration if you&#39;re new to all this</title>
      <link>https://katherinemwood.github.io/post/preregistration/</link>
      <pubDate>Mon, 26 Jun 2017 16:11:46 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/preregistration/</guid>
      <description>How do you know where to start?</description>
    </item>
    
    <item>
      <title>Intro to unit testing in R</title>
      <link>https://katherinemwood.github.io/post/unittesting/</link>
      <pubDate>Mon, 26 Jun 2017 15:46:23 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/unittesting/</guid>
      <description>The best way to know if something works is to test it.</description>
    </item>
    
    <item>
      <title>Intro to R Notebooks</title>
      <link>https://katherinemwood.github.io/post/r-notebooks/</link>
      <pubDate>Mon, 26 Jun 2017 15:36:22 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/r-notebooks/</guid>
      <description>Combine executable code, math formatting, and nice markdown in one easy place.</description>
    </item>
    
    <item>
      <title>Data in the raw: Violin plots</title>
      <link>https://katherinemwood.github.io/post/violins/</link>
      <pubDate>Mon, 26 Jun 2017 15:27:06 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/violins/</guid>
      <description>Violin plots are a way to present more information about your raw data.</description>
    </item>
    
    <item>
      <title>Intro to Bootstrapping</title>
      <link>https://katherinemwood.github.io/post/bootstrapping/</link>
      <pubDate>Mon, 26 Jun 2017 15:02:58 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/bootstrapping/</guid>
      <description>Bootstrapping is a powerful and intuitive technique.</description>
    </item>
    
    <item>
      <title>5 Minute Simulation: Variation in effect size estimates</title>
      <link>https://katherinemwood.github.io/post/effect_size_variance/</link>
      <pubDate>Mon, 26 Jun 2017 13:54:20 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/effect_size_variance/</guid>
      <description>How much variability can you expect from the effect size estimate in a single study?</description>
    </item>
    
    <item>
      <title>Open Science in Practice</title>
      <link>https://katherinemwood.github.io/post/gams/</link>
      <pubDate>Mon, 26 Jun 2017 13:48:35 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/gams/</guid>
      <description>A look inside an open science workflow.</description>
    </item>
    
    <item>
      <title>5 Minute Simulation: Lonely Cards</title>
      <link>https://katherinemwood.github.io/post/card_simulation/</link>
      <pubDate>Mon, 26 Jun 2017 12:34:18 -0500</pubDate>
      
      <guid>https://katherinemwood.github.io/post/card_simulation/</guid>
      <description>Solving a probability question with simulation.</description>
    </item>
    
    <item>
      <title>Effect Size Calculator</title>
      <link>https://katherinemwood.github.io/projects/effect_sizes/</link>
      <pubDate>Tue, 02 May 2017 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/projects/effect_sizes/</guid>
      <description>This is a Shiny application that brings the beloved effect size calculator spreadsheets by Daniel Lakens online. The application will produce as many common effect sizes as possible given the information available.</description>
    </item>
    
    <item>
      <title>One Dark Sky</title>
      <link>https://katherinemwood.github.io/projects/darksky/</link>
      <pubDate>Mon, 02 May 2016 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/projects/darksky/</guid>
      <description>This is a short exploratory data analysis project using historical weather data accessed using the Darksky API. The analysis was done in an RNotebook.</description>
    </item>
    
    <item>
      <title>Reconciling change blindness with long-term memory for objects</title>
      <link>https://katherinemwood.github.io/publications/cbltm/</link>
      <pubDate>Mon, 01 Feb 2016 19:47:09 +0200</pubDate>
      
      <guid>https://katherinemwood.github.io/publications/cbltm/</guid>
      <description>Abstract How can we reconcile remarkably precise long-term memory for thousands of images with failures to detect changes to similar images? We explored whether people can use detailed, long-term memory to improve change detection performance. Subjects studied a set of images of objects and then performed recognition and change detection tasks with those images. Recognition memory performance exceeded change detection performance, even when a single familiar object in the post-change display consistently indicated the change location.</description>
    </item>
    
    <item>
      <title>One day build: Shiny effect sizes</title>
      <link>https://katherinemwood.github.io/post/effect-size-calculator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://katherinemwood.github.io/post/effect-size-calculator/</guid>
      <description>Take your effect sizes on the go.</description>
    </item>
    
  </channel>
</rss>